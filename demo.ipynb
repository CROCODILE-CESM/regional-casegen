{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up a regional MOM6 run within CESM framework\n",
    "\n",
    "There are three main sections: \n",
    "1. First we create the MOM6 experiment using the [regional-mom6](https://github.com/COSIMA/regional-mom6/) package. This puts everything we need into two repositories, referred to as the `mom_run_dir` and `mom_input_dir`. These contain all of the configuration files (`MOM_input` etc.) and netcdf input files (`hgrid.nc`, OBC segments etc.) respectively. An `experiment` object is also created within the notebook, containing all the information we need about the regional mom6 setup to pass onto CESM.\n",
    "\n",
    "2. A new MOM6 CESM case is created in the usual way by cloning the CESM repo and running the `create_case` command. \n",
    "\n",
    "3. We modify the new CESM case to work with the regional mom6 configuration we prepared earlier. We pass the path to this CESM run and the experiment object to the `setup_cesm` function, which carries out all the required modifications \n",
    "\n",
    "This is very much a work in progress! The goal in the short term was to get something working and make it nice later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 1: Setup up you MOM6 regional experiment\n",
    "\n",
    "This follows the normal workflow, copied from the `reanalysis_forced.ipynb` demo of [regional-mom6](https://github.com/COSIMA/regional-mom6/) but modified for a domain around Hawaii. See the documentation of the package for details and documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regional_mom6 as rmom6\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Choose our domain, define workspace paths\n",
    "\n",
    "To make sure that things are working I'd recommend starting with the default example defined below. If this runs ok, then change to a domain of your choice and hopefully it runs ok too! If not, check the [README](https://github.com/COSIMA/regional-mom6/blob/main/README.md) and [documentation](https://regional-mom6.readthedocs.io/) for troubleshooting tips.\n",
    "\n",
    "You can log in and use [this GUI](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/download) to find the lat/lon of your domain and copy paste below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = \"hawaii-demo\"\n",
    "\n",
    "latitude_extent = [16., 27]\n",
    "longitude_extent = [192, 209]\n",
    "\n",
    "date_range = [\"2020-01-01 00:00:00\", \"2020-02-01 00:00:00\"]\n",
    "\n",
    "## Place where all your input files go \n",
    "input_dir = Path(f\"/glade/work/abarnes/inputdirs/{expt_name}/\")\n",
    "\n",
    "## Directory where you'll run the experiment from\n",
    "run_dir = Path(f\"/glade/u/home/abarnes/mom6_rundirs/{expt_name}/\")\n",
    "\n",
    "## Directory where compiled FRE tools are located (needed for construction of mask tables)\n",
    "toolpath_dir = Path(\"/glade/u/home/manishrv/documents/regional-mom6-dev/FRE-NCtools\")\n",
    "\n",
    "## Path to where your raw ocean forcing files are stored\n",
    "glorys_path = Path(f\"/glade/work/abarnes/downloads/{expt_name}\" )\n",
    "\n",
    "## if directories don't exist, create them\n",
    "for path in (run_dir, glorys_path, input_dir):\n",
    "    os.makedirs(str(path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Make experiment object\n",
    "The `regional_mom6.experiment` contains the regional domain basics, and also generates the horizontal and vertical grids, `hgrid` and `vgrid` respectively, and sets up the directory structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = rmom6.experiment(\n",
    "    longitude_extent = longitude_extent,\n",
    "    latitude_extent = latitude_extent,\n",
    "    date_range = date_range,\n",
    "    resolution = 0.05,\n",
    "    number_vertical_layers = 75,\n",
    "    layer_thickness_ratio = 10,\n",
    "    depth = 4500,\n",
    "    minimum_depth = 5,\n",
    "    mom_run_dir = run_dir,\n",
    "    mom_input_dir = input_dir,\n",
    "    toolpath_dir = toolpath_dir,\n",
    "    read_existing_grids = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare ocean forcing data\n",
    "\n",
    "We need to cut out our ocean forcing. The package expects an initial condition and one time-dependent segment per non-land boundary. Naming convention is `\"east_unprocessed\"` for segments and `\"ic_unprocessed\"` for the initial condition.\n",
    "\n",
    "In this notebook, we are forcing with the Copernicus Marine \"Glorys\" reanalysis dataset. There's a function in the `mom6-regional` package that generates a bash script to download the correct boundary forcing files for your experiment. First, you will need to create an account with Copernicus, and then call `copernicusmarine login` to set up your login details on your machine. Then you can run the `get_glorys_data.sh` bash script.\n",
    "\n",
    "The function is called `get_glorys_rectangular` because the fully automated setup is only supported for domains with boundaries parallel to lines of longitude and latitude. To download more complex domain shapes you can call `rmom6.get_glorys_data` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.get_glorys_rectangular(\n",
    "    raw_boundaries_path=glorys_path,\n",
    "    boundaries=[\"north\", \"south\", \"east\", \"west\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up bathymetry\n",
    "\n",
    "Similarly to ocean forcing, we point the experiment's `setup_bathymetry` method at the location of the file of choice and also provide the variable names. We don't need to preprocess the bathymetry since it is simply a two-dimensional field and is easier to deal with. Afterwards you can inspect `expt.bathymetry` to have a look at the regional domain.\n",
    "\n",
    "After running this cell, your input directory will contain other bathymetry-related things like the ocean mosaic and mask table too. The mask table defaults to a 10x10 layout and can be modified later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.setup_bathymetry(\n",
    "    bathymetry_path='/glade/work/abarnes/downloads/GEBCO_2024.nc', \n",
    "    longitude_coordinate_name='lon',\n",
    "    latitude_coordinate_name='lat',\n",
    "    vertical_coordinate_name='elevation'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out your domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output",
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "expt.bathymetry.depth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 5: Handle the ocean forcing - where the magic happens\n",
    "\n",
    "This cuts out and interpolates the initial condition as well as all boundaries (unless you don't pass it boundaries).\n",
    "\n",
    "The dictionary maps the MOM6 variable names to what they're called in your ocean input file. Notice how for GLORYS, the horizontal dimensions are `latitude` and `longitude`, vs `xh`, `yh`, `xq`, `yq` for MOM6. This is because for an 'A' grid type tracers share the grid with velocities so there's no difference.\n",
    "\n",
    "If one of your segments is land, you can delete its string from the 'boundaries' list. You'll need to update MOM_input to reflect this though so it knows how many segments to look for, and their orientations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from the GLORYS variables and dimensions to the MOM6 ones\n",
    "ocean_varnames = {\"time\": \"time\",\n",
    "                  \"yh\": \"latitude\",\n",
    "                  \"xh\": \"longitude\",\n",
    "                  \"zl\": \"depth\",\n",
    "                  \"eta\": \"zos\",\n",
    "                  \"u\": \"uo\",\n",
    "                  \"v\": \"vo\",\n",
    "                  \"tracers\": {\"salt\": \"so\", \"temp\": \"thetao\"}\n",
    "                  }\n",
    "\n",
    "# Set up the initial condition\n",
    "expt.initial_condition(\n",
    "    glorys_path / \"ic_unprocessed.nc\", # directory where the unprocessed initial condition is stored, as defined earlier\n",
    "    ocean_varnames,\n",
    "    arakawa_grid=\"A\"\n",
    "    )    \n",
    "\n",
    "# Set up the four boundary conditions. Remember that in the glorys_path, we have four boundary files names north_unprocessed.nc etc. \n",
    "expt.rectangular_boundaries(\n",
    "        glorys_path,\n",
    "        ocean_varnames,\n",
    "        boundaries = [\"south\", \"north\", \"west\", \"east\"],\n",
    "        arakawa_grid = \"A\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Modify the default input directory to make a (hopefully) runnable configuration out of the box\n",
    "\n",
    "This step copies the default directory and modifies the `MOM_layout` files to match your experiment by inserting the right number of x, y points and CPU layout.\n",
    "\n",
    "To run MOM6 using the [payu infrastructure](https://github.com/payu-org/payu), provide the keyword argument `using_payu = True` to the `setup_run_directory` method and an example `config.yaml` file will be appear in the run directory. The `config.yaml` file needs to be modified manually to add the locations of executables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.setup_run_directory(surface_forcing = \"jra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 2: Create a blank CESM run\n",
    "\n",
    "So far I've used Alper's [GUI](https://github.com/ESMCI/visualCaseGen?tab=readme-ov-file) branch of CESM. Clone respective branch of CESM and then run the generate case command. Below is the command I used to generate a global, MOM6 only run forced with JRA data atmosphere\n",
    "\n",
    "`/glade/u/home/abarnes/cesm-runs/visualCaseGen/cesm2_3_beta17_gui/cime/scripts/create_newcase --compset 1850_DATM%JRA_SLND_SICE_MOM6_SROF_SGLC_SWAV --res TL319_t232 --case /glade/u/home/abarnes/cesm-runs/cases/hawaii --machine derecho --run-unsupported --project p93300012 --non-local`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the path where the new CESM config lives\n",
    "CESM_path = Path(f\"/glade/u/home/abarnes/cesm-runs/cases/{expt_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 3: Modify the CESM run to make it regional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cesm_tools import setup_cesm\n",
    "\n",
    "setup_cesm(expt, CESM_path,\"p93300612\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now hopefully doing the usual \n",
    "\n",
    "`./case.setup && ./case.build && ./case.submit` \n",
    "\n",
    "should at least run. Of course from here you'll have a lot of other things to fiddle around with to make it run *well!* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alster",
   "language": "python",
   "name": "alster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
